{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from semopy import Model, Optimizer\n",
    "\n",
    "# Define the path to your dataset\n",
    "current_directory = os.getcwd()\n",
    "excel_path = os.path.join(current_directory, '01-data', 'TAM_DEF.xlsx')\n",
    "summary_dir = os.path.join(current_directory, '04-summary')\n",
    "\n",
    "# Ensure the summary directory exists\n",
    "if not os.path.exists(summary_dir):\n",
    "    os.makedirs(summary_dir)\n",
    "\n",
    "# Load the dataset from the \"Cleaned_final\" sheet\n",
    "try:\n",
    "    df = pd.read_excel(excel_path, sheet_name='Cleaned_final')\n",
    "    print(\"Dataset loaded successfully from 'Cleaned_final' sheet.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found. Please check the file path: {excel_path}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error during dataset loading: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Work+ personal average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from semopy import Model, Optimizer\n",
    "\n",
    "\n",
    "# Generate summary statistics for the dataset\n",
    "summary_stats = df.describe()\n",
    "print(\"Summary statistics of the dataset:\")\n",
    "print(summary_stats)\n",
    "\n",
    "# Define the SEM model with the Yvar_Work_Personal and revised hypotheses\n",
    "model_desc = \"\"\"\n",
    "# Latent variables\n",
    "Trust =~ VAR11_PRIVACY_AI_Protect_Data + VAR16_ETHICS_AI_Developed_Ethical\n",
    "Ease_of_Use =~ VAR02_CG_AI_Training_Opo + VAR12_PRIVACY_AI_Give_Consent_Data_Usage\n",
    "Fairness =~ VAR25_FAIRNESS_AI_Treats_All_Fair + VAR26_FAIRNESS_Should_Reduce_Bias\n",
    "\n",
    "# Direct relationships with Yvar_Work_Personal\n",
    "Yvar_Work_Personal ~ Trust\n",
    "Yvar_Work_Personal ~ Ease_of_Use\n",
    "Yvar_Work_Personal ~ Fairness\n",
    "\n",
    "# Relationships with latent variables\n",
    "Trust ~ VAR11_PRIVACY_AI_Protect_Data\n",
    "Trust ~ VAR16_ETHICS_AI_Developed_Ethical\n",
    "Ease_of_Use ~ VAR02_CG_AI_Training_Opo\n",
    "\n",
    "# Covariances (as needed)\n",
    "Trust ~~ Ease_of_Use\n",
    "Trust ~~ Fairness\n",
    "Ease_of_Use ~~ Fairness\n",
    "\"\"\"\n",
    "\n",
    "# Create the model and load the dataset into the model\n",
    "try:\n",
    "    model = Model(model_desc)\n",
    "    model.load_dataset(df)\n",
    "    print(\"Model created and dataset loaded into the model successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during model creation or dataset loading: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Optimize the model\n",
    "try:\n",
    "    optim = Optimizer(model)\n",
    "    optim.optimize()\n",
    "    print(\"Model optimization completed successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during model optimization: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Extract the results\n",
    "try:\n",
    "    results = model.inspect()\n",
    "    # Convert any \"Not estimated\" or non-numeric values to NaN\n",
    "    results = results.applymap(lambda x: np.nan if x in [\"Not estimated\", \"-\"] else x)\n",
    "    print(\"Full Results DataFrame:\")\n",
    "    print(results)\n",
    "except Exception as e:\n",
    "    print(f\"Error during results extraction: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Attempt to extract p-values for the paths\n",
    "try:\n",
    "    pvalues = results[['p-value']].apply(pd.to_numeric, errors='coerce')  # Convert to numeric, set errors to NaN\n",
    "    print(\"\\nP-values extracted successfully:\")\n",
    "    print(pvalues)\n",
    "except KeyError:\n",
    "    print(\"\\nUnable to extract p-values. Check the results DataFrame above for available data.\")\n",
    "    exit()\n",
    "\n",
    "# Define hypotheses and their corresponding paths based on revised hypotheses\n",
    "hypothesis_criteria = [\n",
    "    (\"Hypothesis 1: Trust influences Yvar_Work_Personal\", 'Yvar_Work_Personal ~ Trust'),\n",
    "    (\"Hypothesis 2: Ease of Use influences Yvar_Work_Personal\", 'Yvar_Work_Personal ~ Ease_of_Use'),\n",
    "    (\"Hypothesis 3: Fairness influences Yvar_Work_Personal\", 'Yvar_Work_Personal ~ Fairness'),\n",
    "    (\"Hypothesis 4: Privacy and Data Protection influence Trust\", 'Trust ~ VAR11_PRIVACY_AI_Protect_Data'),\n",
    "    (\"Hypothesis 5: Ethical Considerations influence Trust\", 'Trust ~ VAR16_ETHICS_AI_Developed_Ethical'),\n",
    "    (\"Hypothesis 6: Training Opportunities influence Ease of Use\", 'Ease_of_Use ~ VAR02_CG_AI_Training_Opo')\n",
    "]\n",
    "\n",
    "# Determine whether each hypothesis is accepted or rejected\n",
    "accepted_hypotheses = []\n",
    "rejected_hypotheses = []\n",
    "\n",
    "for hyp, path in hypothesis_criteria:\n",
    "    matching_paths = [p for p in results['lval'] + \" ~ \" + results['rval'] if path in p]\n",
    "    if matching_paths:\n",
    "        try:\n",
    "            p_value = pvalues.loc[results['lval'] == matching_paths[0].split(\" ~ \")[0], 'p-value'].values[0]\n",
    "            if not np.isnan(p_value) and p_value < 0.05:\n",
    "                accepted_hypotheses.append(hyp)\n",
    "            else:\n",
    "                rejected_hypotheses.append(hyp)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during p-value extraction for {path}: {e}\")\n",
    "            rejected_hypotheses.append(hyp)\n",
    "    else:\n",
    "        print(f\"Path {path} not found in results. Please check the available paths.\")\n",
    "        rejected_hypotheses.append(hyp)\n",
    "\n",
    "# Output the results\n",
    "print(\"\\nAccepted Hypotheses:\")\n",
    "for hyp in accepted_hypotheses:\n",
    "    print(hyp)\n",
    "\n",
    "print(\"\\nRejected Hypotheses:\")\n",
    "for hyp in rejected_hypotheses:\n",
    "    print(hyp)\n",
    "\n",
    "# Save the results and summary statistics to Excel\n",
    "with pd.ExcelWriter(summary_path) as writer:\n",
    "    summary_stats.to_excel(writer, sheet_name='Summary Statistics')\n",
    "    results.to_excel(writer, sheet_name='SEM Results')\n",
    "    pvalues.to_excel(writer, sheet_name='P-Values')\n",
    "    \n",
    "    # Write accepted and rejected hypotheses\n",
    "    pd.DataFrame({'Accepted Hypotheses': accepted_hypotheses}).to_excel(writer, sheet_name='Accepted Hypotheses', index=False)\n",
    "    pd.DataFrame({'Rejected Hypotheses': rejected_hypotheses}).to_excel(writer, sheet_name='Rejected Hypotheses', index=False)\n",
    "\n",
    "print(f\"Summary statistics and SEM results saved to {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model by Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from semopy import Model, Optimizer\n",
    "\n",
    "# Combine \"Gen X\" and \"Boomer\" into one segment called \"Gen X & Boomer\"\n",
    "df['Generation'] = df['Generation'].replace({'Gen X': 'Gen X & Boomer', 'Boomer': 'Gen X & Boomer'})\n",
    "\n",
    "# Get unique generations after combining\n",
    "generations = df['Generation'].unique()\n",
    "print(f\"Found generations: {generations}\")\n",
    "\n",
    "# Loop through each generation and run the SEM model\n",
    "for generation in generations:\n",
    "    df_gen = df[df['Generation'] == generation]\n",
    "    \n",
    "    # Generate summary statistics for the subset\n",
    "    summary_stats = df_gen.describe()\n",
    "    print(f\"Summary statistics for {generation}:\")\n",
    "    print(summary_stats)\n",
    "\n",
    "    # Define the SEM model with the Yvar_Work_Personal and revised hypotheses\n",
    "    model_desc = \"\"\"\n",
    "    # Latent variables\n",
    "    Trust =~ VAR11_PRIVACY_AI_Protect_Data + VAR16_ETHICS_AI_Developed_Ethical\n",
    "    Ease_of_Use =~ VAR02_CG_AI_Training_Opo + VAR12_PRIVACY_AI_Give_Consent_Data_Usage\n",
    "    Fairness =~ VAR25_FAIRNESS_AI_Treats_All_Fair + VAR26_FAIRNESS_Should_Reduce_Bias\n",
    "\n",
    "    # Direct relationships with Yvar_Work_Personal\n",
    "  Yvar_Work_Personal ~ Trust\n",
    "  Yvar_Work_Personal ~ Ease_of_Use\n",
    "  Yvar_Work_Personal ~ Fairness\n",
    "\n",
    "    # Relationships with latent variables\n",
    "    Trust ~ VAR11_PRIVACY_AI_Protect_Data\n",
    "    Trust ~ VAR16_ETHICS_AI_Developed_Ethical\n",
    "    Ease_of_Use ~ VAR02_CG_AI_Training_Opo\n",
    "\n",
    "    # Covariances (as needed)\n",
    "    Trust ~~ Ease_of_Use\n",
    "    Trust ~~ Fairness\n",
    "    Ease_of_Use ~~ Fairness\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the model and load the dataset into the model\n",
    "    try:\n",
    "        model = Model(model_desc)\n",
    "        model.load_dataset(df_gen)\n",
    "        print(f\"Model created and dataset loaded into the model successfully for {generation}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model creation or dataset loading for {generation}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Optimize the model\n",
    "    try:\n",
    "        optim = Optimizer(model)\n",
    "        optim.optimize()\n",
    "        print(f\"Model optimization completed successfully for {generation}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model optimization for {generation}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Extract the results\n",
    "    try:\n",
    "        results = model.inspect()\n",
    "        # Convert any \"Not estimated\" or non-numeric values to NaN\n",
    "        results = results.applymap(lambda x: np.nan if x in [\"Not estimated\", \"-\"] else x)\n",
    "        print(f\"Full Results DataFrame for {generation}:\")\n",
    "        print(results)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during results extraction for {generation}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Attempt to extract p-values for the paths\n",
    "    try:\n",
    "        pvalues = results[['p-value']].apply(pd.to_numeric, errors='coerce')  # Convert to numeric, set errors to NaN\n",
    "        print(f\"\\nP-values extracted successfully for {generation}:\")\n",
    "        print(pvalues)\n",
    "    except KeyError:\n",
    "        print(f\"\\nUnable to extract p-values for {generation}. Check the results DataFrame above for available data.\")\n",
    "        continue\n",
    "\n",
    "    # Define hypotheses and their corresponding paths based on revised hypotheses\n",
    "    hypothesis_criteria = [\n",
    "        (\"Hypothesis 1: Trust influences Yvar_Work_Personal\", 'Yvar_Work_Personal ~ Trust'),\n",
    "        (\"Hypothesis 2: Ease of Use influences Yvar_Work_Personal\", 'Yvar_Work_Personal ~ Ease_of_Use'),\n",
    "        (\"Hypothesis 3: Fairness influences Yvar_Work_Personal\", 'Yvar_Work_Personal ~ Fairness'),\n",
    "        (\"Hypothesis 4: Privacy and Data Protection influence Trust\", 'Trust ~ VAR11_PRIVACY_AI_Protect_Data'),\n",
    "        (\"Hypothesis 5: Ethical Considerations influence Trust\", 'Trust ~ VAR16_ETHICS_AI_Developed_Ethical'),\n",
    "        (\"Hypothesis 6: Training Opportunities influence Ease of Use\", 'Ease_of_Use ~ VAR02_CG_AI_Training_Opo')\n",
    "    ]\n",
    "\n",
    "    # Determine whether each hypothesis is accepted or rejected\n",
    "    accepted_hypotheses = []\n",
    "    rejected_hypotheses = []\n",
    "\n",
    "    for hyp, path in hypothesis_criteria:\n",
    "        matching_paths = [p for p in results['lval'] + \" ~ \" + results['rval'] if path in p]\n",
    "        if matching_paths:\n",
    "            try:\n",
    "                p_value = pvalues.loc[results['lval'] == matching_paths[0].split(\" ~ \")[0], 'p-value'].values[0]\n",
    "                if not np.isnan(p_value) and p_value < 0.05:\n",
    "                    accepted_hypotheses.append(hyp)\n",
    "                else:\n",
    "                    rejected_hypotheses.append(hyp)\n",
    "            except Exception as e:\n",
    "                print(f\"Error during p-value extraction for {path} in {generation}: {e}\")\n",
    "                rejected_hypotheses.append(hyp)\n",
    "        else:\n",
    "            print(f\"Path {path} not found in results for {generation}. Please check the available paths.\")\n",
    "            rejected_hypotheses.append(hyp)\n",
    "\n",
    "    # Output the results\n",
    "    print(f\"\\nAccepted Hypotheses for {generation}:\")\n",
    "    for hyp in accepted_hypotheses:\n",
    "        print(hyp)\n",
    "\n",
    "    print(f\"\\nRejected Hypotheses for {generation}:\")\n",
    "    for hyp in rejected_hypotheses:\n",
    "        print(hyp)\n",
    "\n",
    "    # Save the results and summary statistics to Excel for each generation\n",
    "    gen_summary_path = os.path.join(summary_dir, f'model_summary_{generation}.xlsx')\n",
    "    with pd.ExcelWriter(gen_summary_path) as writer:\n",
    "        summary_stats.to_excel(writer, sheet_name='Summary Statistics')\n",
    "        results.to_excel(writer, sheet_name='SEM Results')\n",
    "        pvalues.to_excel(writer, sheet_name='P-Values')\n",
    "        \n",
    "        # Write accepted and rejected hypotheses\n",
    "        pd.DataFrame({'Accepted Hypotheses': accepted_hypotheses}).to_excel(writer, sheet_name='Accepted Hypotheses', index=False)\n",
    "        pd.DataFrame({'Rejected Hypotheses': rejected_hypotheses}).to_excel(writer, sheet_name='Rejected Hypotheses', index=False)\n",
    "\n",
    "    print(f\"Summary statistics and SEM results saved to {gen_summary_path} for {generation}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# by CS experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Fisher Information Matrix is not PD.Moore-Penrose inverse will be used instead of Cholesky decomposition. See 10.1109/TSP.2012.2208105.\n",
      "/var/folders/ft/dwmcjbnd0b35z5n9yksp4jfh0000gn/T/ipykernel_10736/1332403472.py:59: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  results = results.applymap(lambda x: np.nan if x in [\"Not estimated\", \"-\", None] else x)\n",
      "WARNING:root:Fisher Information Matrix is not PD.Moore-Penrose inverse will be used instead of Cholesky decomposition. See 10.1109/TSP.2012.2208105.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CS_experience_rollup segments: ['Experienced' 'Novice' 'No Experience']\n",
      "Summary statistics for Experienced:\n",
      "       VAR01_CG_Training  VAR02_CG_AI_Training_Opo  \\\n",
      "count         250.000000                250.000000   \n",
      "mean            3.536000                  4.000000   \n",
      "std             1.245354                  0.878114   \n",
      "min             1.000000                  1.000000   \n",
      "25%             3.000000                  4.000000   \n",
      "50%             4.000000                  4.000000   \n",
      "75%             4.000000                  5.000000   \n",
      "max             5.000000                  5.000000   \n",
      "\n",
      "       VAR03_CG_AI_Training_Access  VAR04_CG_AI_Training_helps_skills  \\\n",
      "count                   250.000000                         250.000000   \n",
      "mean                      4.188000                           3.988000   \n",
      "std                       0.909927                           0.929144   \n",
      "min                       1.000000                           1.000000   \n",
      "25%                       4.000000                           4.000000   \n",
      "50%                       4.000000                           4.000000   \n",
      "75%                       5.000000                           5.000000   \n",
      "max                       5.000000                           5.000000   \n",
      "\n",
      "       VAR05_CG_AI_Training_Supported  VAR06_ED_AI_Training_needed  \\\n",
      "count                      250.000000                   250.000000   \n",
      "mean                         3.516000                     4.084000   \n",
      "std                          1.123742                     0.980198   \n",
      "min                          1.000000                     1.000000   \n",
      "25%                          3.000000                     4.000000   \n",
      "50%                          4.000000                     4.000000   \n",
      "75%                          4.000000                     5.000000   \n",
      "max                          5.000000                     5.000000   \n",
      "\n",
      "       VAR07_JOB_Postive_Import  VAR08_JOB_Enchance_Job_Security  \\\n",
      "count                250.000000                       250.000000   \n",
      "mean                   3.344000                         3.188000   \n",
      "std                    1.186294                         1.229105   \n",
      "min                    1.000000                         1.000000   \n",
      "25%                    2.000000                         2.000000   \n",
      "50%                    4.000000                         3.000000   \n",
      "75%                    4.000000                         4.000000   \n",
      "max                    5.000000                         5.000000   \n",
      "\n",
      "       VAR09_WORKFORCE_AI_Job_loss  \\\n",
      "count                   250.000000   \n",
      "mean                      3.688000   \n",
      "std                       1.154116   \n",
      "min                       1.000000   \n",
      "25%                       3.000000   \n",
      "50%                       4.000000   \n",
      "75%                       5.000000   \n",
      "max                       5.000000   \n",
      "\n",
      "       VAR10_WORKFORCE_AI_Increase_Opportunity_Growth  ...  \\\n",
      "count                                      250.000000  ...   \n",
      "mean                                         3.576000  ...   \n",
      "std                                          1.114087  ...   \n",
      "min                                          1.000000  ...   \n",
      "25%                                          3.000000  ...   \n",
      "50%                                          4.000000  ...   \n",
      "75%                                          4.000000  ...   \n",
      "max                                          5.000000  ...   \n",
      "\n",
      "       VAR27_FAIRNESS_Access_to_All  VAR28_PERSONAL_Enhances_Experience  \\\n",
      "count                    250.000000                          250.000000   \n",
      "mean                       4.396000                            3.696000   \n",
      "std                        0.830629                            1.117398   \n",
      "min                        1.000000                            1.000000   \n",
      "25%                        4.000000                            3.000000   \n",
      "50%                        5.000000                            4.000000   \n",
      "75%                        5.000000                            4.000000   \n",
      "max                        5.000000                            5.000000   \n",
      "\n",
      "       VAR29_PERONAL_Improves_CS_quality  Yvar_USE_AI_Work  \\\n",
      "count                         250.000000        250.000000   \n",
      "mean                            3.684000          4.048000   \n",
      "std                             1.133704          1.129068   \n",
      "min                             1.000000          1.000000   \n",
      "25%                             3.000000          4.000000   \n",
      "50%                             4.000000          4.000000   \n",
      "75%                             5.000000          5.000000   \n",
      "max                             5.000000          5.000000   \n",
      "\n",
      "       Yvar_USE_AI_Personal  Yvar_Work_Personal  Yvar_TopBox_Work  \\\n",
      "count            250.000000          250.000000        250.000000   \n",
      "mean               3.876000            3.962000          0.812000   \n",
      "std                1.110657            0.982557          0.391496   \n",
      "min                1.000000            1.000000          0.000000   \n",
      "25%                4.000000            3.500000          1.000000   \n",
      "50%                4.000000            4.000000          1.000000   \n",
      "75%                5.000000            5.000000          1.000000   \n",
      "max                5.000000            5.000000          1.000000   \n",
      "\n",
      "       Yvar_Topbox_personal  Yvar_TopBox_Work_Personal  Count  \n",
      "count            250.000000                 250.000000  250.0  \n",
      "mean               0.752000                   0.660000    1.0  \n",
      "std                0.432718                   0.474659    0.0  \n",
      "min                0.000000                   0.000000    1.0  \n",
      "25%                1.000000                   0.000000    1.0  \n",
      "50%                1.000000                   1.000000    1.0  \n",
      "75%                1.000000                   1.000000    1.0  \n",
      "max                1.000000                   1.000000    1.0  \n",
      "\n",
      "[8 rows x 36 columns]\n",
      "Model created and dataset loaded into the model successfully for Experienced.\n",
      "Model optimization completed successfully for Experienced.\n",
      "Full Results DataFrame for Experienced:\n",
      "                                        lval  op  \\\n",
      "0              VAR11_PRIVACY_AI_Protect_Data   ~   \n",
      "1          VAR16_ETHICS_AI_Developed_Ethical   ~   \n",
      "2                   VAR02_CG_AI_Training_Opo   ~   \n",
      "3                                      Trust   ~   \n",
      "4                                      Trust   ~   \n",
      "5                                Ease_of_Use   ~   \n",
      "6   VAR12_PRIVACY_AI_Give_Consent_Data_Usage   ~   \n",
      "7          VAR25_FAIRNESS_AI_Treats_All_Fair   ~   \n",
      "8          VAR26_FAIRNESS_Should_Reduce_Bias   ~   \n",
      "9                         Yvar_Work_Personal   ~   \n",
      "10                        Yvar_Work_Personal   ~   \n",
      "11                        Yvar_Work_Personal   ~   \n",
      "12                                     Trust  ~~   \n",
      "13                                     Trust  ~~   \n",
      "14                                     Trust  ~~   \n",
      "15                               Ease_of_Use  ~~   \n",
      "16                               Ease_of_Use  ~~   \n",
      "17                                  Fairness  ~~   \n",
      "18                  VAR02_CG_AI_Training_Opo  ~~   \n",
      "19             VAR11_PRIVACY_AI_Protect_Data  ~~   \n",
      "20         VAR16_ETHICS_AI_Developed_Ethical  ~~   \n",
      "21  VAR12_PRIVACY_AI_Give_Consent_Data_Usage  ~~   \n",
      "22         VAR25_FAIRNESS_AI_Treats_All_Fair  ~~   \n",
      "23         VAR26_FAIRNESS_Should_Reduce_Bias  ~~   \n",
      "24                        Yvar_Work_Personal  ~~   \n",
      "\n",
      "                                        rval  Estimate  Std. Err    z-value  \\\n",
      "0                                      Trust  1.000000       NaN        NaN   \n",
      "1                                      Trust  0.000000  0.004864   0.000000   \n",
      "2                                Ease_of_Use  1.000000       NaN        NaN   \n",
      "3              VAR11_PRIVACY_AI_Protect_Data  0.000000  0.028115   0.000000   \n",
      "4          VAR16_ETHICS_AI_Developed_Ethical  0.000000  0.068072   0.000000   \n",
      "5                   VAR02_CG_AI_Training_Opo  0.000000  1.371068   0.000000   \n",
      "6                                Ease_of_Use  0.140625  0.645644   0.217806   \n",
      "7                                   Fairness  1.000000       NaN        NaN   \n",
      "8                                   Fairness  0.257056  4.045052   0.063548   \n",
      "9                                      Trust  0.092606  0.330401   0.280282   \n",
      "10                               Ease_of_Use  0.507812  0.548582   0.925682   \n",
      "11                                  Fairness  0.179665  2.803797   0.064079   \n",
      "12                               Ease_of_Use  0.000000  0.037772   0.000000   \n",
      "13                                  Fairness  0.000000  0.053233   0.000000   \n",
      "14                                     Trust  0.050000  0.294618   0.169712   \n",
      "15                                  Fairness  0.000000  0.038332   0.000000   \n",
      "16                               Ease_of_Use  0.050000  0.615390   0.081249   \n",
      "17                                  Fairness  0.050000  0.806399   0.062004   \n",
      "18                  VAR02_CG_AI_Training_Opo  0.384000  0.580853   0.661096   \n",
      "19             VAR11_PRIVACY_AI_Protect_Data  0.779392  0.318159   2.449692   \n",
      "20         VAR16_ETHICS_AI_Developed_Ethical  0.699808  0.062593  11.180340   \n",
      "21  VAR12_PRIVACY_AI_Give_Consent_Data_Usage  0.730528  0.066339  11.012060   \n",
      "22         VAR25_FAIRNESS_AI_Treats_All_Fair  0.880928  0.809792   1.087845   \n",
      "23         VAR26_FAIRNESS_Should_Reduce_Bias  0.609768  0.076228   7.999287   \n",
      "24                        Yvar_Work_Personal  0.480778  0.157939   3.044082   \n",
      "\n",
      "         p-value  \n",
      "0            NaN  \n",
      "1   1.000000e+00  \n",
      "2            NaN  \n",
      "3   1.000000e+00  \n",
      "4   1.000000e+00  \n",
      "5   1.000000e+00  \n",
      "6   8.275804e-01  \n",
      "7            NaN  \n",
      "8   9.493299e-01  \n",
      "9   7.792612e-01  \n",
      "10  3.546113e-01  \n",
      "11  9.489072e-01  \n",
      "12  1.000000e+00  \n",
      "13  1.000000e+00  \n",
      "14  8.652370e-01  \n",
      "15  1.000000e+00  \n",
      "16  9.352437e-01  \n",
      "17  9.505596e-01  \n",
      "18  5.085505e-01  \n",
      "19  1.429783e-02  \n",
      "20  0.000000e+00  \n",
      "21  0.000000e+00  \n",
      "22  2.766634e-01  \n",
      "23  1.332268e-15  \n",
      "24  2.333914e-03  \n",
      "\n",
      "P-values extracted successfully for Experienced:\n",
      "         p-value\n",
      "0            NaN\n",
      "1   1.000000e+00\n",
      "2            NaN\n",
      "3   1.000000e+00\n",
      "4   1.000000e+00\n",
      "5   1.000000e+00\n",
      "6   8.275804e-01\n",
      "7            NaN\n",
      "8   9.493299e-01\n",
      "9   7.792612e-01\n",
      "10  3.546113e-01\n",
      "11  9.489072e-01\n",
      "12  1.000000e+00\n",
      "13  1.000000e+00\n",
      "14  8.652370e-01\n",
      "15  1.000000e+00\n",
      "16  9.352437e-01\n",
      "17  9.505596e-01\n",
      "18  5.085505e-01\n",
      "19  1.429783e-02\n",
      "20  0.000000e+00\n",
      "21  0.000000e+00\n",
      "22  2.766634e-01\n",
      "23  1.332268e-15\n",
      "24  2.333914e-03\n",
      "\n",
      "Accepted Hypotheses for Experienced:\n",
      "\n",
      "Rejected Hypotheses for Experienced:\n",
      "Hypothesis 1: Trust influences Yvar_Work_Personal\n",
      "Hypothesis 2: Ease of Use influences Yvar_Work_Personal\n",
      "Hypothesis 3: Fairness influences Yvar_Work_Personal\n",
      "Hypothesis 4: AI-related training and career growth opportunities influence Ease of Use\n",
      "Hypothesis 5: Security and safety features enhance trust in AI\n",
      "Hypothesis 6: Ethical design and positive social impact increase trust in AI\n",
      "Summary statistics and SEM results saved to /Users/danramirez/mbs-structural-equation-modeling/04-summary/model_summary_Experienced.xlsx for Experienced.\n",
      "Summary statistics for Novice:\n",
      "       VAR01_CG_Training  VAR02_CG_AI_Training_Opo  \\\n",
      "count         244.000000                244.000000   \n",
      "mean            3.565574                  3.680328   \n",
      "std             1.292509                  1.105664   \n",
      "min             1.000000                  1.000000   \n",
      "25%             3.000000                  3.000000   \n",
      "50%             4.000000                  4.000000   \n",
      "75%             5.000000                  4.000000   \n",
      "max             5.000000                  5.000000   \n",
      "\n",
      "       VAR03_CG_AI_Training_Access  VAR04_CG_AI_Training_helps_skills  \\\n",
      "count                   244.000000                         244.000000   \n",
      "mean                      4.073770                           3.827869   \n",
      "std                       0.978519                           0.953163   \n",
      "min                       1.000000                           1.000000   \n",
      "25%                       4.000000                           3.000000   \n",
      "50%                       4.000000                           4.000000   \n",
      "75%                       5.000000                           4.000000   \n",
      "max                       5.000000                           5.000000   \n",
      "\n",
      "       VAR05_CG_AI_Training_Supported  VAR06_ED_AI_Training_needed  \\\n",
      "count                      244.000000                   244.000000   \n",
      "mean                         3.364754                     4.069672   \n",
      "std                          1.224807                     0.955417   \n",
      "min                          1.000000                     1.000000   \n",
      "25%                          2.000000                     4.000000   \n",
      "50%                          4.000000                     4.000000   \n",
      "75%                          4.000000                     5.000000   \n",
      "max                          5.000000                     5.000000   \n",
      "\n",
      "       VAR07_JOB_Postive_Import  VAR08_JOB_Enchance_Job_Security  \\\n",
      "count                244.000000                       244.000000   \n",
      "mean                   3.036885                         2.770492   \n",
      "std                    1.208114                         1.225832   \n",
      "min                    1.000000                         1.000000   \n",
      "25%                    2.000000                         2.000000   \n",
      "50%                    3.000000                         3.000000   \n",
      "75%                    4.000000                         4.000000   \n",
      "max                    5.000000                         5.000000   \n",
      "\n",
      "       VAR09_WORKFORCE_AI_Job_loss  \\\n",
      "count                   244.000000   \n",
      "mean                      3.672131   \n",
      "std                       1.285837   \n",
      "min                       1.000000   \n",
      "25%                       3.000000   \n",
      "50%                       4.000000   \n",
      "75%                       5.000000   \n",
      "max                       5.000000   \n",
      "\n",
      "       VAR10_WORKFORCE_AI_Increase_Opportunity_Growth  ...  \\\n",
      "count                                      244.000000  ...   \n",
      "mean                                         3.311475  ...   \n",
      "std                                          1.244457  ...   \n",
      "min                                          1.000000  ...   \n",
      "25%                                          2.000000  ...   \n",
      "50%                                          4.000000  ...   \n",
      "75%                                          4.000000  ...   \n",
      "max                                          5.000000  ...   \n",
      "\n",
      "       VAR27_FAIRNESS_Access_to_All  VAR28_PERSONAL_Enhances_Experience  \\\n",
      "count                    244.000000                          244.000000   \n",
      "mean                       4.344262                            3.598361   \n",
      "std                        0.886761                            1.141509   \n",
      "min                        1.000000                            1.000000   \n",
      "25%                        4.000000                            3.000000   \n",
      "50%                        5.000000                            4.000000   \n",
      "75%                        5.000000                            4.000000   \n",
      "max                        5.000000                            5.000000   \n",
      "\n",
      "       VAR29_PERONAL_Improves_CS_quality  Yvar_USE_AI_Work  \\\n",
      "count                         244.000000        244.000000   \n",
      "mean                            3.512295          3.581967   \n",
      "std                             1.198358          1.350751   \n",
      "min                             1.000000          1.000000   \n",
      "25%                             3.000000          2.000000   \n",
      "50%                             4.000000          4.000000   \n",
      "75%                             4.000000          5.000000   \n",
      "max                             5.000000          5.000000   \n",
      "\n",
      "       Yvar_USE_AI_Personal  Yvar_Work_Personal  Yvar_TopBox_Work  \\\n",
      "count            244.000000          244.000000        244.000000   \n",
      "mean               3.540984            3.561475          0.692623   \n",
      "std                1.293526            1.202839          0.462355   \n",
      "min                1.000000            1.000000          0.000000   \n",
      "25%                2.000000            2.500000          0.000000   \n",
      "50%                4.000000            4.000000          1.000000   \n",
      "75%                4.000000            4.500000          1.000000   \n",
      "max                5.000000            5.000000          1.000000   \n",
      "\n",
      "       Yvar_Topbox_personal  Yvar_TopBox_Work_Personal  Count  \n",
      "count            244.000000                 244.000000  244.0  \n",
      "mean               0.676230                   0.594262    1.0  \n",
      "std                0.468875                   0.492044    0.0  \n",
      "min                0.000000                   0.000000    1.0  \n",
      "25%                0.000000                   0.000000    1.0  \n",
      "50%                1.000000                   1.000000    1.0  \n",
      "75%                1.000000                   1.000000    1.0  \n",
      "max                1.000000                   1.000000    1.0  \n",
      "\n",
      "[8 rows x 36 columns]\n",
      "Model created and dataset loaded into the model successfully for Novice.\n",
      "Model optimization completed successfully for Novice.\n",
      "Full Results DataFrame for Novice:\n",
      "                                        lval  op  \\\n",
      "0              VAR11_PRIVACY_AI_Protect_Data   ~   \n",
      "1          VAR16_ETHICS_AI_Developed_Ethical   ~   \n",
      "2                   VAR02_CG_AI_Training_Opo   ~   \n",
      "3                                      Trust   ~   \n",
      "4                                      Trust   ~   \n",
      "5                                Ease_of_Use   ~   \n",
      "6   VAR12_PRIVACY_AI_Give_Consent_Data_Usage   ~   \n",
      "7          VAR25_FAIRNESS_AI_Treats_All_Fair   ~   \n",
      "8          VAR26_FAIRNESS_Should_Reduce_Bias   ~   \n",
      "9                         Yvar_Work_Personal   ~   \n",
      "10                        Yvar_Work_Personal   ~   \n",
      "11                        Yvar_Work_Personal   ~   \n",
      "12                                     Trust  ~~   \n",
      "13                                     Trust  ~~   \n",
      "14                                     Trust  ~~   \n",
      "15                               Ease_of_Use  ~~   \n",
      "16                               Ease_of_Use  ~~   \n",
      "17                                  Fairness  ~~   \n",
      "18                  VAR02_CG_AI_Training_Opo  ~~   \n",
      "19             VAR11_PRIVACY_AI_Protect_Data  ~~   \n",
      "20         VAR16_ETHICS_AI_Developed_Ethical  ~~   \n",
      "21  VAR12_PRIVACY_AI_Give_Consent_Data_Usage  ~~   \n",
      "22         VAR25_FAIRNESS_AI_Treats_All_Fair  ~~   \n",
      "23         VAR26_FAIRNESS_Should_Reduce_Bias  ~~   \n",
      "24                        Yvar_Work_Personal  ~~   \n",
      "\n",
      "                                        rval  Estimate  Std. Err    z-value  \\\n",
      "0                                      Trust  1.000000       NaN        NaN   \n",
      "1                                      Trust  0.000000  0.004741   0.000000   \n",
      "2                                Ease_of_Use  1.000000       NaN        NaN   \n",
      "3              VAR11_PRIVACY_AI_Protect_Data  0.000000  0.025352   0.000000   \n",
      "4          VAR16_ETHICS_AI_Developed_Ethical  0.000000  0.065531   0.000000   \n",
      "5                   VAR02_CG_AI_Training_Opo  0.000000  0.313300   0.000000   \n",
      "6                                Ease_of_Use  0.415706  0.758240   0.548251   \n",
      "7                                   Fairness  1.000000       NaN        NaN   \n",
      "8                                   Fairness  0.239241  3.658669   0.065390   \n",
      "9                                      Trust  0.260446  0.077659   3.353735   \n",
      "10                               Ease_of_Use  0.643949  0.512226   1.257158   \n",
      "11                                  Fairness  0.246835  3.804636   0.064878   \n",
      "12                               Ease_of_Use  0.000000  0.043143   0.000000   \n",
      "13                                  Fairness  0.000000  0.050574   0.000000   \n",
      "14                                     Trust  0.050000  0.193628   0.258228   \n",
      "15                                  Fairness  0.000000  0.043865   0.000000   \n",
      "16                               Ease_of_Use  0.050000  0.211937   0.235919   \n",
      "17                                  Fairness  0.050000  0.786740   0.063553   \n",
      "18                  VAR02_CG_AI_Training_Opo  0.608741  0.223205   2.727272   \n",
      "19             VAR11_PRIVACY_AI_Protect_Data  0.726980  0.212960   3.413694   \n",
      "20         VAR16_ETHICS_AI_Developed_Ethical  0.691044  0.062564  11.045361   \n",
      "21  VAR12_PRIVACY_AI_Give_Consent_Data_Usage  0.757558  0.078110   9.698612   \n",
      "22         VAR25_FAIRNESS_AI_Treats_All_Fair  0.809426  0.789712   1.024963   \n",
      "23         VAR26_FAIRNESS_Should_Reduce_Bias  0.620893  0.072009   8.622393   \n",
      "24                        Yvar_Work_Personal  0.720446  0.122122   5.899382   \n",
      "\n",
      "         p-value  \n",
      "0            NaN  \n",
      "1   1.000000e+00  \n",
      "2            NaN  \n",
      "3   1.000000e+00  \n",
      "4   1.000000e+00  \n",
      "5   1.000000e+00  \n",
      "6   5.835198e-01  \n",
      "7            NaN  \n",
      "8   9.478635e-01  \n",
      "9   7.972877e-04  \n",
      "10  2.086965e-01  \n",
      "11  9.482715e-01  \n",
      "12  1.000000e+00  \n",
      "13  1.000000e+00  \n",
      "14  7.962313e-01  \n",
      "15  1.000000e+00  \n",
      "16  8.134957e-01  \n",
      "17  9.493258e-01  \n",
      "18  6.386037e-03  \n",
      "19  6.408854e-04  \n",
      "20  0.000000e+00  \n",
      "21  0.000000e+00  \n",
      "22  3.053805e-01  \n",
      "23  0.000000e+00  \n",
      "24  3.648648e-09  \n",
      "\n",
      "P-values extracted successfully for Novice:\n",
      "         p-value\n",
      "0            NaN\n",
      "1   1.000000e+00\n",
      "2            NaN\n",
      "3   1.000000e+00\n",
      "4   1.000000e+00\n",
      "5   1.000000e+00\n",
      "6   5.835198e-01\n",
      "7            NaN\n",
      "8   9.478635e-01\n",
      "9   7.972877e-04\n",
      "10  2.086965e-01\n",
      "11  9.482715e-01\n",
      "12  1.000000e+00\n",
      "13  1.000000e+00\n",
      "14  7.962313e-01\n",
      "15  1.000000e+00\n",
      "16  8.134957e-01\n",
      "17  9.493258e-01\n",
      "18  6.386037e-03\n",
      "19  6.408854e-04\n",
      "20  0.000000e+00\n",
      "21  0.000000e+00\n",
      "22  3.053805e-01\n",
      "23  0.000000e+00\n",
      "24  3.648648e-09\n",
      "\n",
      "Accepted Hypotheses for Novice:\n",
      "Hypothesis 1: Trust influences Yvar_Work_Personal\n",
      "Hypothesis 2: Ease of Use influences Yvar_Work_Personal\n",
      "Hypothesis 3: Fairness influences Yvar_Work_Personal\n",
      "\n",
      "Rejected Hypotheses for Novice:\n",
      "Hypothesis 4: AI-related training and career growth opportunities influence Ease of Use\n",
      "Hypothesis 5: Security and safety features enhance trust in AI\n",
      "Hypothesis 6: Ethical design and positive social impact increase trust in AI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ft/dwmcjbnd0b35z5n9yksp4jfh0000gn/T/ipykernel_10736/1332403472.py:59: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  results = results.applymap(lambda x: np.nan if x in [\"Not estimated\", \"-\", None] else x)\n",
      "WARNING:root:Fisher Information Matrix is not PD.Moore-Penrose inverse will be used instead of Cholesky decomposition. See 10.1109/TSP.2012.2208105.\n",
      "/var/folders/ft/dwmcjbnd0b35z5n9yksp4jfh0000gn/T/ipykernel_10736/1332403472.py:59: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  results = results.applymap(lambda x: np.nan if x in [\"Not estimated\", \"-\", None] else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics and SEM results saved to /Users/danramirez/mbs-structural-equation-modeling/04-summary/model_summary_Novice.xlsx for Novice.\n",
      "Summary statistics for No Experience:\n",
      "       VAR01_CG_Training  VAR02_CG_AI_Training_Opo  \\\n",
      "count         335.000000                 335.00000   \n",
      "mean            3.185075                   3.78209   \n",
      "std             1.316097                   0.93356   \n",
      "min             1.000000                   1.00000   \n",
      "25%             2.000000                   3.00000   \n",
      "50%             4.000000                   4.00000   \n",
      "75%             4.000000                   4.00000   \n",
      "max             5.000000                   5.00000   \n",
      "\n",
      "       VAR03_CG_AI_Training_Access  VAR04_CG_AI_Training_helps_skills  \\\n",
      "count                   335.000000                         335.000000   \n",
      "mean                      4.053731                           3.767164   \n",
      "std                       0.894147                           0.963152   \n",
      "min                       1.000000                           1.000000   \n",
      "25%                       4.000000                           3.000000   \n",
      "50%                       4.000000                           4.000000   \n",
      "75%                       5.000000                           4.000000   \n",
      "max                       5.000000                           5.000000   \n",
      "\n",
      "       VAR05_CG_AI_Training_Supported  VAR06_ED_AI_Training_needed  \\\n",
      "count                      335.000000                   335.000000   \n",
      "mean                         2.952239                     4.092537   \n",
      "std                          1.157164                     0.882517   \n",
      "min                          1.000000                     1.000000   \n",
      "25%                          2.000000                     4.000000   \n",
      "50%                          3.000000                     4.000000   \n",
      "75%                          4.000000                     5.000000   \n",
      "max                          5.000000                     5.000000   \n",
      "\n",
      "       VAR07_JOB_Postive_Import  VAR08_JOB_Enchance_Job_Security  \\\n",
      "count                335.000000                       335.000000   \n",
      "mean                   2.952239                         2.629851   \n",
      "std                    1.154574                         1.086253   \n",
      "min                    1.000000                         1.000000   \n",
      "25%                    2.000000                         2.000000   \n",
      "50%                    3.000000                         2.000000   \n",
      "75%                    4.000000                         3.000000   \n",
      "max                    5.000000                         5.000000   \n",
      "\n",
      "       VAR09_WORKFORCE_AI_Job_loss  \\\n",
      "count                   335.000000   \n",
      "mean                      3.952239   \n",
      "std                       1.051426   \n",
      "min                       1.000000   \n",
      "25%                       4.000000   \n",
      "50%                       4.000000   \n",
      "75%                       5.000000   \n",
      "max                       5.000000   \n",
      "\n",
      "       VAR10_WORKFORCE_AI_Increase_Opportunity_Growth  ...  \\\n",
      "count                                      335.000000  ...   \n",
      "mean                                         3.232836  ...   \n",
      "std                                          1.144943  ...   \n",
      "min                                          1.000000  ...   \n",
      "25%                                          2.000000  ...   \n",
      "50%                                          3.000000  ...   \n",
      "75%                                          4.000000  ...   \n",
      "max                                          5.000000  ...   \n",
      "\n",
      "       VAR27_FAIRNESS_Access_to_All  VAR28_PERSONAL_Enhances_Experience  \\\n",
      "count                    335.000000                          335.000000   \n",
      "mean                       4.438806                            3.379104   \n",
      "std                        0.805103                            1.098248   \n",
      "min                        1.000000                            1.000000   \n",
      "25%                        4.000000                            3.000000   \n",
      "50%                        5.000000                            4.000000   \n",
      "75%                        5.000000                            4.000000   \n",
      "max                        5.000000                            5.000000   \n",
      "\n",
      "       VAR29_PERONAL_Improves_CS_quality  Yvar_USE_AI_Work  \\\n",
      "count                         335.000000        335.000000   \n",
      "mean                            3.405970          3.328358   \n",
      "std                             1.161751          1.373270   \n",
      "min                             1.000000          1.000000   \n",
      "25%                             3.000000          2.000000   \n",
      "50%                             4.000000          4.000000   \n",
      "75%                             4.000000          4.000000   \n",
      "max                             5.000000          5.000000   \n",
      "\n",
      "       Yvar_USE_AI_Personal  Yvar_Work_Personal  Yvar_TopBox_Work  \\\n",
      "count            335.000000          335.000000        335.000000   \n",
      "mean               3.402985            3.365672          0.614925   \n",
      "std                1.313902            1.187453          0.487341   \n",
      "min                1.000000            1.000000          0.000000   \n",
      "25%                2.000000            2.500000          0.000000   \n",
      "50%                4.000000            3.500000          1.000000   \n",
      "75%                4.000000            4.000000          1.000000   \n",
      "max                5.000000            5.000000          1.000000   \n",
      "\n",
      "       Yvar_Topbox_personal  Yvar_TopBox_Work_Personal  Count  \n",
      "count            335.000000                 335.000000  335.0  \n",
      "mean               0.620896                   0.486567    1.0  \n",
      "std                0.485890                   0.500567    0.0  \n",
      "min                0.000000                   0.000000    1.0  \n",
      "25%                0.000000                   0.000000    1.0  \n",
      "50%                1.000000                   0.000000    1.0  \n",
      "75%                1.000000                   1.000000    1.0  \n",
      "max                1.000000                   1.000000    1.0  \n",
      "\n",
      "[8 rows x 36 columns]\n",
      "Model created and dataset loaded into the model successfully for No Experience.\n",
      "Model optimization completed successfully for No Experience.\n",
      "Full Results DataFrame for No Experience:\n",
      "                                        lval  op  \\\n",
      "0              VAR11_PRIVACY_AI_Protect_Data   ~   \n",
      "1          VAR16_ETHICS_AI_Developed_Ethical   ~   \n",
      "2                   VAR02_CG_AI_Training_Opo   ~   \n",
      "3                                      Trust   ~   \n",
      "4                                      Trust   ~   \n",
      "5                                Ease_of_Use   ~   \n",
      "6   VAR12_PRIVACY_AI_Give_Consent_Data_Usage   ~   \n",
      "7          VAR25_FAIRNESS_AI_Treats_All_Fair   ~   \n",
      "8          VAR26_FAIRNESS_Should_Reduce_Bias   ~   \n",
      "9                         Yvar_Work_Personal   ~   \n",
      "10                        Yvar_Work_Personal   ~   \n",
      "11                        Yvar_Work_Personal   ~   \n",
      "12                                     Trust  ~~   \n",
      "13                                     Trust  ~~   \n",
      "14                                     Trust  ~~   \n",
      "15                               Ease_of_Use  ~~   \n",
      "16                               Ease_of_Use  ~~   \n",
      "17                                  Fairness  ~~   \n",
      "18                  VAR02_CG_AI_Training_Opo  ~~   \n",
      "19             VAR11_PRIVACY_AI_Protect_Data  ~~   \n",
      "20         VAR16_ETHICS_AI_Developed_Ethical  ~~   \n",
      "21  VAR12_PRIVACY_AI_Give_Consent_Data_Usage  ~~   \n",
      "22         VAR25_FAIRNESS_AI_Treats_All_Fair  ~~   \n",
      "23         VAR26_FAIRNESS_Should_Reduce_Bias  ~~   \n",
      "24                        Yvar_Work_Personal  ~~   \n",
      "\n",
      "                                        rval  Estimate  Std. Err    z-value  \\\n",
      "0                                      Trust  1.000000       NaN        NaN   \n",
      "1                                      Trust  0.000000  0.004806   0.000000   \n",
      "2                                Ease_of_Use  1.000000       NaN        NaN   \n",
      "3              VAR11_PRIVACY_AI_Protect_Data  0.000000  0.018618   0.000000   \n",
      "4          VAR16_ETHICS_AI_Developed_Ethical  0.000000  0.055163   0.000000   \n",
      "5                   VAR02_CG_AI_Training_Opo  0.000000  1.433313   0.000000   \n",
      "6                                Ease_of_Use  0.105829  0.593361   0.178355   \n",
      "7                                   Fairness  1.000000       NaN        NaN   \n",
      "8                                   Fairness  0.255251  3.053461   0.083594   \n",
      "9                                      Trust  0.234764  0.067810   3.462068   \n",
      "10                               Ease_of_Use  0.598415  0.452772   1.321670   \n",
      "11                                  Fairness  0.234112  2.789810   0.083917   \n",
      "12                               Ease_of_Use  0.000000  0.029789   0.000000   \n",
      "13                                  Fairness  0.000000  0.035250   0.000000   \n",
      "14                                     Trust  0.050000  0.152617   0.327618   \n",
      "15                                  Fairness  0.000000  0.031121   0.000000   \n",
      "16                               Ease_of_Use  0.050000  0.731736   0.068331   \n",
      "17                                  Fairness  0.050000  0.611324   0.081790   \n",
      "18                  VAR02_CG_AI_Training_Opo  0.434466  0.661984   0.656310   \n",
      "19             VAR11_PRIVACY_AI_Protect_Data  0.567583  0.167160   3.395447   \n",
      "20         VAR16_ETHICS_AI_Developed_Ethical  0.573954  0.044348  12.942179   \n",
      "21  VAR12_PRIVACY_AI_Give_Consent_Data_Usage  0.676053  0.052759  12.814082   \n",
      "22         VAR25_FAIRNESS_AI_Treats_All_Fair  0.674119  0.613199   1.099348   \n",
      "23         VAR26_FAIRNESS_Should_Reduce_Bias  0.547008  0.058060   9.421375   \n",
      "24                        Yvar_Work_Personal  0.702918  0.245327   2.865236   \n",
      "\n",
      "     p-value  \n",
      "0        NaN  \n",
      "1   1.000000  \n",
      "2        NaN  \n",
      "3   1.000000  \n",
      "4   1.000000  \n",
      "5   1.000000  \n",
      "6   0.858444  \n",
      "7        NaN  \n",
      "8   0.933379  \n",
      "9   0.000536  \n",
      "10  0.186278  \n",
      "11  0.933123  \n",
      "12  1.000000  \n",
      "13  1.000000  \n",
      "14  0.743201  \n",
      "15  1.000000  \n",
      "16  0.945522  \n",
      "17  0.934814  \n",
      "18  0.511625  \n",
      "19  0.000685  \n",
      "20  0.000000  \n",
      "21  0.000000  \n",
      "22  0.271616  \n",
      "23  0.000000  \n",
      "24  0.004167  \n",
      "\n",
      "P-values extracted successfully for No Experience:\n",
      "     p-value\n",
      "0        NaN\n",
      "1   1.000000\n",
      "2        NaN\n",
      "3   1.000000\n",
      "4   1.000000\n",
      "5   1.000000\n",
      "6   0.858444\n",
      "7        NaN\n",
      "8   0.933379\n",
      "9   0.000536\n",
      "10  0.186278\n",
      "11  0.933123\n",
      "12  1.000000\n",
      "13  1.000000\n",
      "14  0.743201\n",
      "15  1.000000\n",
      "16  0.945522\n",
      "17  0.934814\n",
      "18  0.511625\n",
      "19  0.000685\n",
      "20  0.000000\n",
      "21  0.000000\n",
      "22  0.271616\n",
      "23  0.000000\n",
      "24  0.004167\n",
      "\n",
      "Accepted Hypotheses for No Experience:\n",
      "Hypothesis 1: Trust influences Yvar_Work_Personal\n",
      "Hypothesis 2: Ease of Use influences Yvar_Work_Personal\n",
      "Hypothesis 3: Fairness influences Yvar_Work_Personal\n",
      "\n",
      "Rejected Hypotheses for No Experience:\n",
      "Hypothesis 4: AI-related training and career growth opportunities influence Ease of Use\n",
      "Hypothesis 5: Security and safety features enhance trust in AI\n",
      "Hypothesis 6: Ethical design and positive social impact increase trust in AI\n",
      "Summary statistics and SEM results saved to /Users/danramirez/mbs-structural-equation-modeling/04-summary/model_summary_No Experience.xlsx for No Experience.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get unique values in the 'CS_experience_rollup' column\n",
    "cs_experience_segments = df['CS_experience_rollup'].unique()\n",
    "print(f\"Found CS_experience_rollup segments: {cs_experience_segments}\")\n",
    "\n",
    "# Loop through each segment in the 'CS_experience_rollup' column and run the SEM model\n",
    "for segment in cs_experience_segments:\n",
    "    df_segment = df[df['CS_experience_rollup'] == segment]\n",
    "    \n",
    "    # Generate summary statistics for the subset\n",
    "    summary_stats = df_segment.describe()\n",
    "    print(f\"Summary statistics for {segment}:\")\n",
    "    print(summary_stats)\n",
    "\n",
    "    # Define the SEM model with the Yvar_Work_Personal and revised hypotheses\n",
    "    model_desc = \"\"\"\n",
    "    # Latent variables\n",
    "    Trust =~ VAR11_PRIVACY_AI_Protect_Data + VAR16_ETHICS_AI_Developed_Ethical\n",
    "    Ease_of_Use =~ VAR02_CG_AI_Training_Opo + VAR12_PRIVACY_AI_Give_Consent_Data_Usage\n",
    "    Fairness =~ VAR25_FAIRNESS_AI_Treats_All_Fair + VAR26_FAIRNESS_Should_Reduce_Bias\n",
    "\n",
    "    # Direct relationships with Yvar_Work_Personal\n",
    "    Yvar_Work_Personal ~ Trust\n",
    "    Yvar_Work_Personal ~ Ease_of_Use\n",
    "    Yvar_Work_Personal ~ Fairness\n",
    "\n",
    "    # Relationships with latent variables\n",
    "    Trust ~ VAR11_PRIVACY_AI_Protect_Data\n",
    "    Trust ~ VAR16_ETHICS_AI_Developed_Ethical\n",
    "    Ease_of_Use ~ VAR02_CG_AI_Training_Opo\n",
    "\n",
    "    # Covariances (as needed)\n",
    "    Trust ~~ Ease_of_Use\n",
    "    Trust ~~ Fairness\n",
    "    Ease_of_Use ~~ Fairness\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the model and load the dataset into the model\n",
    "    try:\n",
    "        model = Model(model_desc)\n",
    "        model.load_dataset(df_segment)\n",
    "        print(f\"Model created and dataset loaded into the model successfully for {segment}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model creation or dataset loading for {segment}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Optimize the model\n",
    "    try:\n",
    "        optim = Optimizer(model)\n",
    "        optim.optimize()\n",
    "        print(f\"Model optimization completed successfully for {segment}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model optimization for {segment}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Extract the results\n",
    "    try:\n",
    "        results = model.inspect()\n",
    "        # Convert any \"Not estimated\" or non-numeric values to NaN\n",
    "        results = results.applymap(lambda x: np.nan if x in [\"Not estimated\", \"-\", None] else x)\n",
    "        print(f\"Full Results DataFrame for {segment}:\")\n",
    "        print(results)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during results extraction for {segment}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Attempt to extract p-values for the paths\n",
    "    try:\n",
    "        pvalues = results[['p-value']].apply(pd.to_numeric, errors='coerce')  # Convert to numeric, set errors to NaN\n",
    "        print(f\"\\nP-values extracted successfully for {segment}:\")\n",
    "        print(pvalues)\n",
    "    except KeyError:\n",
    "        print(f\"\\nUnable to extract p-values for {segment}. Check the results DataFrame above for available data.\")\n",
    "        continue\n",
    "\n",
    "    # Define hypotheses and their corresponding paths based on revised hypotheses\n",
    "    hypothesis_criteria = [\n",
    "        (\"Hypothesis 1: Trust influences Yvar_Work_Personal\", 'Yvar_Work_Personal ~ Trust'),\n",
    "        (\"Hypothesis 2: Ease of Use influences Yvar_Work_Personal\", 'Yvar_Work_Personal ~ Ease_of_Use'),\n",
    "        (\"Hypothesis 3: Fairness influences Yvar_Work_Personal\", 'Yvar_Work_Personal ~ Fairness'),\n",
    "        (\"Hypothesis 4: AI-related training and career growth opportunities influence Ease of Use\", 'Ease_of_Use ~ VAR02_CG_AI_Training_Opo'),\n",
    "        (\"Hypothesis 5: Security and safety features enhance trust in AI\", 'Trust ~ VAR11_PRIVACY_AI_Protect_Data'),\n",
    "        (\"Hypothesis 6: Ethical design and positive social impact increase trust in AI\", 'Trust ~ VAR16_ETHICS_AI_Developed_Ethical')\n",
    "    ]\n",
    "\n",
    "    # Determine whether each hypothesis is accepted or rejected\n",
    "    accepted_hypotheses = []\n",
    "    rejected_hypotheses = []\n",
    "\n",
    "    for hyp, path in hypothesis_criteria:\n",
    "        matching_paths = [p for p in results['lval'] + \" ~ \" + results['rval'] if path in p]\n",
    "        if matching_paths:\n",
    "            try:\n",
    "                p_value = pvalues.loc[results['lval'] == matching_paths[0].split(\" ~ \")[0], 'p-value'].values[0]\n",
    "                if not np.isnan(p_value) and p_value < 0.05:\n",
    "                    accepted_hypotheses.append(hyp)\n",
    "                else:\n",
    "                    rejected_hypotheses.append(hyp)\n",
    "            except Exception as e:\n",
    "                print(f\"Error during p-value extraction for {path} in {segment}: {e}\")\n",
    "                rejected_hypotheses.append(hyp)\n",
    "        else:\n",
    "            print(f\"Path {path} not found in results for {segment}. Please check the available paths.\")\n",
    "            rejected_hypotheses.append(hyp)\n",
    "\n",
    "    # Output the results\n",
    "    print(f\"\\nAccepted Hypotheses for {segment}:\")\n",
    "    for hyp in accepted_hypotheses:\n",
    "        print(hyp)\n",
    "\n",
    "    print(f\"\\nRejected Hypotheses for {segment}:\")\n",
    "    for hyp in rejected_hypotheses:\n",
    "        print(hyp)\n",
    "\n",
    "    # Save the results and summary statistics to Excel for each segment\n",
    "    segment_summary_path = os.path.join(summary_dir, f'model_summary_{segment}.xlsx')\n",
    "    with pd.ExcelWriter(segment_summary_path) as writer:\n",
    "        summary_stats.to_excel(writer, sheet_name='Summary Statistics')\n",
    "        results.to_excel(writer, sheet_name='SEM Results')\n",
    "        pvalues.to_excel(writer, sheet_name='P-Values')\n",
    "        \n",
    "        # Write accepted and rejected hypotheses\n",
    "        pd.DataFrame({'Accepted Hypotheses': accepted_hypotheses}).to_excel(writer, sheet_name='Accepted Hypotheses', index=False)\n",
    "        pd.DataFrame({'Rejected Hypotheses': rejected_hypotheses}).to_excel(writer, sheet_name='Rejected Hypotheses', index=False)\n",
    "\n",
    "    print(f\"Summary statistics and SEM results saved to {segment_summary_path} for {segment}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
