{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyreadstat\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Paths to input files and output directories\n",
    "current_directory = os.getcwd()\n",
    "sav_file_path = os.path.join(current_directory, '01-data', 'yaleoutput.sav')\n",
    "rename_excel_path = os.path.join(current_directory, '01-data', 'column_rename_mapping.xlsx')\n",
    "output_excel_path = os.path.join(current_directory, '03-output', 'dfyale.xlsx')\n",
    "\n",
    "# Read the .sav file\n",
    "df, meta = pyreadstat.read_sav(sav_file_path)\n",
    "\n",
    "# Drop the specified columns\n",
    "columns_to_drop = ['starttime', 'endtime']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Load the rename mapping from the Excel file\n",
    "rename_df = pd.read_excel(rename_excel_path, sheet_name=\"Mapping\")\n",
    "column_rename_mapping = dict(zip(rename_df['OldName'], rename_df['NewName']))\n",
    "\n",
    "# Rename the columns\n",
    "df.rename(columns=column_rename_mapping, inplace=True)\n",
    "\n",
    "# Drop columns ending in '_select'\n",
    "select_columns = [col for col in df.columns if col.endswith('_select')]\n",
    "df.drop(columns=select_columns, inplace=True)\n",
    "\n",
    "# Get the current year\n",
    "current_year = datetime.now().year\n",
    "\n",
    "# Compute ages based on the current year\n",
    "df['age'] = current_year - df['birthyr']\n",
    "\n",
    "# Define age group bins with \"65+\" as the last group\n",
    "bins = [0, 17, 24, 34, 44, 54, 64, 100]\n",
    "labels = ['0-17', '18-24', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "\n",
    "# Categorize ages into the specified groups\n",
    "df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Convert all numerical columns to floats and round to one decimal place\n",
    "for col in df.select_dtypes(include=['number']).columns:\n",
    "    df[col] = df[col].astype(float).round(1)\n",
    "\n",
    "# Load the grouping data from the Excel file\n",
    "grouping_df = pd.read_excel(rename_excel_path, sheet_name=\"Grouping\")\n",
    "\n",
    "# Mapping functions by suffix\n",
    "suffix_mappings = {\n",
    "    '_impact': dict(zip(grouping_df[grouping_df['Suffix'] == '_impact']['Code'], grouping_df[grouping_df['Suffix'] == '_impact']['Recode'])),\n",
    "    '_confidence': dict(zip(grouping_df[grouping_df['Suffix'] == '_confidence']['Code'], grouping_df[grouping_df['Suffix'] == '_confidence']['Recode'])),\n",
    "    '_important': dict(zip(grouping_df[grouping_df['Suffix'] == '_important']['Code'], grouping_df[grouping_df['Suffix'] == '_important']['Recode'])),\n",
    "    '_likelihood': dict(zip(grouping_df[grouping_df['Suffix'] == '_likelihood']['Code'], grouping_df[grouping_df['Suffix'] == '_likelihood']['Recode'])),\n",
    "    '_agreement': dict(zip(grouping_df[grouping_df['Suffix'] == '_agreement']['Code'], grouping_df[grouping_df['Suffix'] == '_agreement']['Recode'])),\n",
    "    'gender': dict(zip(grouping_df[grouping_df['Suffix'] == 'gender']['Code'], grouping_df[grouping_df['Suffix'] == 'gender']['Recode'])),\n",
    "    'hhi': dict(zip(grouping_df[grouping_df['Suffix'] == 'hhi']['Code'], grouping_df[grouping_df['Suffix'] == 'hhi']['Recode'])),\n",
    "    'marstat': dict(zip(grouping_df[grouping_df['Suffix'] == 'marstat']['Code'], grouping_df[grouping_df['Suffix'] == 'marstat']['Recode'])),\n",
    "    'educ': dict(zip(grouping_df[grouping_df['Suffix'] == 'educ']['Code'], grouping_df[grouping_df['Suffix'] == 'educ']['Recode'])),\n",
    "    'race': dict(zip(grouping_df[grouping_df['Suffix'] == 'race']['Code'], grouping_df[grouping_df['Suffix'] == 'race']['Recode'])),\n",
    "    'state': dict(zip(grouping_df[grouping_df['Suffix'] == 'state']['Code'], grouping_df[grouping_df['Suffix'] == 'state']['Recode'])),\n",
    "    'employ': dict(zip(grouping_df[grouping_df['Suffix'] == 'employ']['Code'], grouping_df[grouping_df['Suffix'] == 'employ']['Recode'])),\n",
    "    'Xvar_politics': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_politics']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_politics']['Recode'])),\n",
    "    'Xvar_Q04_R01_ed_courses_CS': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R01_ed_courses_CS']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R01_ed_courses_CS']['Recode'])),\n",
    "    'Xvar_Q04_R02_ed_undergrad_CS': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R02_ed_undergrad_CS']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R02_ed_undergrad_CS']['Recode'])),\n",
    "    'Xvar_Q04_R03_ed_Grad_CS': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R03_ed_Grad_CS']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R03_ed_Grad_CS']['Recode'])),\n",
    "    'Xvar_Q04_R04_ed_program_exp': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R04_ed_program_exp']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R04_ed_program_exp']['Recode'])),\n",
    "    'Xvar_Q04_R05_ed_none': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R05_ed_none']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R05_ed_none']['Recode'])),\n",
    "    'Y_Q05_SupportAI': dict(zip(grouping_df[grouping_df['Suffix'] == 'Y_Q05_SupportAI']['Code'], grouping_df[grouping_df['Suffix'] == 'Y_Q05_SupportAI']['Recode'])),\n",
    "    'Y_Q17_SupportDevHighlevelAI': dict(zip(grouping_df[grouping_df['Suffix'] == 'Y_Q17_SupportDevHighlevelAI']['Code'], grouping_df[grouping_df['Suffix'] == 'Y_Q17_SupportDevHighlevelAI']['Recode']))\n",
    "}\n",
    "\n",
    "# Function to recode columns based on suffix\n",
    "def apply_mapping(df, mapping_dict, suffix):\n",
    "    for col in df.columns:\n",
    "        if col.endswith(suffix):\n",
    "            df[col] = df[col].replace(mapping_dict)\n",
    "\n",
    "# Apply mappings for each suffix\n",
    "for suffix, mapping_dict in suffix_mappings.items():\n",
    "    apply_mapping(df, mapping_dict, suffix)\n",
    "\n",
    "# List of columns to be one-hot encoded\n",
    "columns_to_encode = ['Xvar_politics', 'Xvar_Q04_R01_ed_courses_CS', 'Xvar_Q04_R02_ed_undergrad_CS', 'Xvar_Q04_R03_ed_Grad_CS', 'Xvar_Q04_R04_ed_program_exp', 'Xvar_Q04_R05_ed_none']\n",
    "\n",
    "# Apply one-hot encoding to categorical columns, which will use 0 and 1\n",
    "df_dummies = pd.get_dummies(df, columns=columns_to_encode, drop_first=False)\n",
    "\n",
    "# Convert all Boolean columns to 0/1\n",
    "bool_columns = df_dummies.select_dtypes(include=['bool']).columns\n",
    "df_dummies[bool_columns] = df_dummies[bool_columns].astype(int)\n",
    "\n",
    "# Drop unwanted columns\n",
    "columns_to_drop = ['birthyr', 'pid7', 'votereg', 'ideo5', 'newsint', 'religpew', 'pew_churatd', 'pew_bornagain', 'pew_religimp', 'pew_prayer', 'Q03new_treat', 'q05b_treat', 'q12a_treat', 'q12_treat', 'q15_treat', 'Xvar_Q05b','Xvar_Q04_R05_ed_none_No','Xvar_Q04_R04_ed_program_exp_No','Xvar_Q04_R03_ed_Grad_CS_No','Xvar_Q04_R02_ed_undergrad_CS_No','Xvar_Q04_R01_ed_courses_CS_No']\n",
    "df_dummies = df_dummies.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Add the 'NA' category to all categorical columns and then fill missing values\n",
    "for col in df_dummies.select_dtypes(include='category').columns:\n",
    "    df_dummies[col] = df_dummies[col].cat.add_categories(['NA'])\n",
    "df_dummies = df_dummies.fillna('NA')\n",
    "\n",
    "weight_column = 'weight'\n",
    "\n",
    "# Identify columns starting with \"Xvar\" or \"Y_\"\n",
    "columns_to_weight = [col for col in df_dummies.columns if col.startswith('Xvar') or col.startswith('Y_')]\n",
    "\n",
    "# Ensure the columns are converted to numeric or boolean types before applying weights\n",
    "for col in columns_to_weight:\n",
    "    # Check if the column is categorical using isinstance with pd.CategoricalDtype\n",
    "    if isinstance(df_dummies[col].dtype, pd.CategoricalDtype):\n",
    "        df_dummies[col] = df_dummies[col].cat.codes\n",
    "    # Convert boolean columns to integers (0/1)\n",
    "    elif pd.api.types.is_bool_dtype(df_dummies[col]):\n",
    "        df_dummies[col] = df_dummies[col].astype(int)\n",
    "    # Convert remaining columns to numeric, coercing errors to NaN\n",
    "    df_dummies[col] = pd.to_numeric(df_dummies[col], errors='coerce')\n",
    "\n",
    "# Now apply the weight from the weight column to the identified columns\n",
    "for col in columns_to_weight:\n",
    "    df_dummies[col] = df_dummies[col] * df_dummies[weight_column]\n",
    "\n",
    "# Save the modified DataFrame to an Excel file\n",
    "df_dummies.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(f\"DataFrame with renamed columns is saved to {output_excel_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/danramirez/mbs-structural-equation-modeling/data_file.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m current_directory \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[1;32m      7\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_directory, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_file.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Adjust the file name and path as necessary\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# List of specific endings to group by\u001b[39;00m\n\u001b[1;32m     11\u001b[0m endings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGovt_War_challenges_important\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI_Challenges_likelihood\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI_employee_Challenge_likelihood\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI_ethics_important\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI_innovation_important\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI_innovation_likelihood\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI_Law_likelihood\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI_risk_impact\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIHarm_likelihood\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeneral_harm_likelihood\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeneral_risk_impact\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGovt_War_challenges\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGovt_War_likelihood\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMgmt_Govt_confidence\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMgmt_NGO_confidence\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMgmt_Tech_confidence \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNatural_Disaster_likelihood\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNatural_risk_impact\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSocialEco_likelihood\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPI_Govt_confidence\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPI_NGO_confidence\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPI_Tech_confidence\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSocialEco_risk_impact\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m ]\n",
      "File \u001b[0;32m~/mbs-structural-equation-modeling/.venv/lib/python3.11/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
      "File \u001b[0;32m~/mbs-structural-equation-modeling/.venv/lib/python3.11/site-packages/pandas/io/excel/_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1557\u001b[0m         )\n",
      "File \u001b[0;32m~/mbs-structural-equation-modeling/.venv/lib/python3.11/site-packages/pandas/io/excel/_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/mbs-structural-equation-modeling/.venv/lib/python3.11/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/danramirez/mbs-structural-equation-modeling/data_file.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from semopy import Model\n",
    "\n",
    "# Load the data\n",
    "current_directory = os.getcwd()\n",
    "survey = os.path.join(current_directory, '03-output', 'dfyale.xlsx')\n",
    "df = pd.read_excel(survey)\n",
    "\n",
    "# List of specific endings to group by\n",
    "endings = [\n",
    "\"Govt_War_challenges_important\",\"AI_Challenges_likelihood\",\"AI_employee_Challenge_likelihood\",\"AI_ethics_important\",\"AI_innovation_important\",\"AI_innovation_likelihood\",\"AI_Law_likelihood\",\"AI_risk_impact\",\"AIHarm_likelihood\",\"General_harm_likelihood\",\"General_risk_impact\",\"Govt_War_challenges\",\"Govt_War_likelihood\",\"Mgmt_Govt_confidence\",\"Mgmt_NGO_confidence\",\"Mgmt_Tech_confidence \",\"Natural_Disaster_likelihood\",\"Natural_risk_impact\",\"SocialEco_likelihood\",\"PI_Govt_confidence\",\"PI_NGO_confidence\",\"PI_Tech_confidence\",\"SocialEco_risk_impact\"\n",
    "]\n",
    "\n",
    "# Dictionary to store columns for each group\n",
    "grouped_columns = {ending: [] for ending in endings}\n",
    "\n",
    "# Assign columns to each group based on their endings\n",
    "for col in df.columns:\n",
    "    for ending in endings:\n",
    "        if col.endswith(ending):\n",
    "            grouped_columns[ending].append(col)\n",
    "\n",
    "# Sum values in each group to create new columns\n",
    "for ending, cols in grouped_columns.items():\n",
    "    if cols:\n",
    "        df[f'Grouped_{ending}'] = df[cols].sum(axis=1)\n",
    "\n",
    "# Define the SEM model using the grouped variables\n",
    "grouped_vars = [f'Grouped_{ending}' for ending in endings if grouped_columns[ending]]\n",
    "\n",
    "model_desc = \" \\n\".join([f\"{var} =~ {' + '.join(grouped_columns[ending])}\" for ending, var in zip(endings, grouped_vars) if grouped_columns[ending]]) + \"\"\"\n",
    "\n",
    "# Structural Model\n",
    "# Define your dependent variable, adjust 'Dependent_Var' to your actual dependent column name\n",
    "Dependent_Var ~ \"\"\" + \" + \".join(grouped_vars)\n",
    "\n",
    "# Create the SEM model, fit it, and load the dataset\n",
    "model = Model(model_desc)\n",
    "model.load_dataset(df)\n",
    "\n",
    "# Optimize the model\n",
    "model.fit()\n",
    "\n",
    "# Output results\n",
    "print(model.inspect('estimates'))\n",
    "\n",
    "# Save results to an Excel file\n",
    "results_path = os.path.join(current_directory, 'sem_results.xlsx')\n",
    "with pd.ExcelWriter(results_path) as writer:\n",
    "    df.to_excel(writer, index=False)\n",
    "\n",
    "print(f\"Results saved to: {results_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
