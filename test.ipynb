{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with renamed columns is saved to /Users/danramirez/mbs-structural-equation-modeling/03-output/dfyale.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyreadstat\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Paths to input files and output directories\n",
    "current_directory = os.getcwd()\n",
    "sav_file_path = os.path.join(current_directory, '01-data', 'yaleoutput.sav')\n",
    "rename_excel_path = os.path.join(current_directory, '01-data', 'column_rename_mapping.xlsx')\n",
    "output_excel_path = os.path.join(current_directory, '03-output', 'dfyale.xlsx')\n",
    "\n",
    "# Read the .sav file\n",
    "df, meta = pyreadstat.read_sav(sav_file_path)\n",
    "\n",
    "# Drop the specified columns\n",
    "columns_to_drop = ['starttime', 'endtime']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Load the rename mapping from the Excel file\n",
    "rename_df = pd.read_excel(rename_excel_path, sheet_name=\"Mapping\")\n",
    "column_rename_mapping = dict(zip(rename_df['OldName'], rename_df['NewName']))\n",
    "\n",
    "# Rename the columns\n",
    "df.rename(columns=column_rename_mapping, inplace=True)\n",
    "\n",
    "# Drop columns ending in '_select'\n",
    "select_columns = [col for col in df.columns if col.endswith('_select')]\n",
    "df.drop(columns=select_columns, inplace=True)\n",
    "\n",
    "# Get the current year\n",
    "current_year = datetime.now().year\n",
    "\n",
    "# Compute ages based on the current year\n",
    "df['age'] = current_year - df['birthyr']\n",
    "\n",
    "# Define age group bins with \"65+\" as the last group\n",
    "bins = [0, 17, 24, 34, 44, 54, 64, 100]\n",
    "labels = ['0-17', '18-24', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "\n",
    "# Categorize ages into the specified groups\n",
    "df['Xvar_age_group'] = pd.cut(df['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Convert all numerical columns to floats and round to one decimal place\n",
    "for col in df.select_dtypes(include=['number']).columns:\n",
    "    df[col] = df[col].astype(float).round(1)\n",
    "\n",
    "grouping_df = pd.read_excel(rename_excel_path, sheet_name=\"Grouping\")\n",
    "\n",
    "# Mapping functions by suffix\n",
    "suffix_mappings = {\n",
    "    '_impact': dict(zip(grouping_df[grouping_df['Suffix'] == '_impact']['Code'], grouping_df[grouping_df['Suffix'] == '_impact']['Recode'])),\n",
    "    '_confidence': dict(zip(grouping_df[grouping_df['Suffix'] == '_confidence']['Code'], grouping_df[grouping_df['Suffix'] == '_confidence']['Recode'])),\n",
    "    '_important': dict(zip(grouping_df[grouping_df['Suffix'] == '_important']['Code'], grouping_df[grouping_df['Suffix'] == '_important']['Recode'])),\n",
    "    '_likelihood': dict(zip(grouping_df[grouping_df['Suffix'] == '_likelihood']['Code'], grouping_df[grouping_df['Suffix'] == '_likelihood']['Recode'])),\n",
    "    '_agreement': dict(zip(grouping_df[grouping_df['Suffix'] == '_agreement']['Code'], grouping_df[grouping_df['Suffix'] == '_agreement']['Recode'])),\n",
    "    'gender': dict(zip(grouping_df[grouping_df['Suffix'] == 'gender']['Code'], grouping_df[grouping_df['Suffix'] == 'gender']['Recode'])),\n",
    "    'hhi': dict(zip(grouping_df[grouping_df['Suffix'] == 'hhi']['Code'], grouping_df[grouping_df['Suffix'] == 'hhi']['Recode'])),\n",
    "    'marstat': dict(zip(grouping_df[grouping_df['Suffix'] == 'marstat']['Code'], grouping_df[grouping_df['Suffix'] == 'marstat']['Recode'])),\n",
    "    'hhi': dict(zip(grouping_df[grouping_df['Suffix'] == 'hhi']['Code'], grouping_df[grouping_df['Suffix'] == 'hhi']['Recode'])),\n",
    "    'educ': dict(zip(grouping_df[grouping_df['Suffix'] == 'educ']['Code'], grouping_df[grouping_df['Suffix'] == 'educ']['Recode'])),\n",
    "    'race': dict(zip(grouping_df[grouping_df['Suffix'] == 'race']['Code'], grouping_df[grouping_df['Suffix'] == 'race']['Recode'])),\n",
    "    'state': dict(zip(grouping_df[grouping_df['Suffix'] == 'state']['Code'], grouping_df[grouping_df['Suffix'] == 'state']['Recode'])),\n",
    "    'employ': dict(zip(grouping_df[grouping_df['Suffix'] == 'employ']['Code'], grouping_df[grouping_df['Suffix'] == 'employ']['Recode'])),\n",
    "    'Xvar_politics': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_politics']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_politics']['Recode'])),\n",
    "    'Xvar_Q04_R01_ed_courses_CS': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R01_ed_courses_CS']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R01_ed_courses_CS']['Recode'])),\n",
    "    'Xvar_Q04_R02_ed_undergrad_CS': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R02_ed_undergrad_CS']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R02_ed_undergrad_CS']['Recode'])),\n",
    "    'Xvar_Q04_R03_ed_Grad_CS': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R03_ed_Grad_CS']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R03_ed_Grad_CS']['Recode'])),\n",
    "    'Xvar_Q04_R04_ed_program_exp': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R04_ed_program_exp']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R04_ed_program_exp']['Recode'])),\n",
    "    'Xvar_Q04_R05_ed_none': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R05_ed_none']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_R05_ed_none']['Recode'])),\n",
    "    'Y_Q05_SupportAI': dict(zip(grouping_df[grouping_df['Suffix'] == 'Y_Q05_SupportAI']['Code'], grouping_df[grouping_df['Suffix'] == 'Y_Q05_SupportAI']['Recode'])),\n",
    "    'Y_Q17_SupportDevHighlevelAI': dict(zip(grouping_df[grouping_df['Suffix'] == 'Y_Q17_SupportDevHighlevelAI']['Code'], grouping_df[grouping_df['Suffix'] == 'Y_Q17_SupportDevHighlevelAI']['Recode']))\n",
    "}\n",
    "\n",
    "# Function to recode columns based on suffix\n",
    "def apply_mapping(df, mapping_dict, suffix):\n",
    "    for col in df.columns:\n",
    "        if col.endswith(suffix):\n",
    "            df[col] = df[col].replace(mapping_dict)\n",
    "\n",
    "# Apply mappings for each suffix\n",
    "for suffix, mapping_dict in suffix_mappings.items():\n",
    "    apply_mapping(df, mapping_dict, suffix)\n",
    "\n",
    "# List of columns to be one-hot encoded\n",
    "columns_to_encode = ['Xvar_age_group','Xvar_politics', 'Xvar_Q04_R01_ed_courses_CS', 'Xvar_Q04_R02_ed_undergrad_CS', 'Xvar_Q04_R03_ed_Grad_CS', 'Xvar_Q04_R04_ed_program_exp', 'Xvar_Q04_R05_ed_none']\n",
    "\n",
    "# Apply one-hot encoding to categorical columns, which will use 0 and 1\n",
    "df_dummies = pd.get_dummies(df, columns=columns_to_encode, drop_first=False)\n",
    "\n",
    "# Convert all Boolean columns to 0/1\n",
    "bool_columns = df_dummies.select_dtypes(include=['bool']).columns\n",
    "df_dummies[bool_columns] = df_dummies[bool_columns].astype(int)\n",
    "\n",
    "columns_to_drop = ['birthyr','pid7','votereg','ideo5','newsint','religpew','pew_churatd','pew_bornagain','pew_religimp','pew_prayer','Q03new_treat','q05b_treat','q12a_treat','q12_treat','q15_treat','Xvar_Q05b']\n",
    "\n",
    "df_dummies = df_dummies.drop(columns=columns_to_drop, errors='ignore')\n",
    "df_dummies = df_dummies.fillna('NA')\n",
    "\n",
    "\n",
    "# Save the modified DataFrame to an Excel file\n",
    "df_dummies.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(f\"DataFrame with renamed columns is saved to {output_excel_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 73\u001b[0m\n\u001b[1;32m     71\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_directory, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     72\u001b[0m graph_output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_directory, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msem_model_graph_unfiltered.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_output_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Export PCA scores and loadings to Excel for detailed analysis\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mExcelWriter(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_directory, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpca_scores_and_loadings.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mas\u001b[39;00m writer:\n",
      "File \u001b[0;32m~/mbs-structural-equation-modeling/.venv/lib/python3.11/site-packages/pydot/core.py:1587\u001b[0m, in \u001b[0;36mDot.__init__.<locals>.new_method\u001b[0;34m(path, f, prog, encoding)\u001b[0m\n\u001b[1;32m   1585\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_method\u001b[39m(path, f\u001b[38;5;241m=\u001b[39mfrmt, prog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Refer to docstring of method `write.`\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1587\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mbs-structural-equation-modeling/.venv/lib/python3.11/site-packages/pydot/core.py:1662\u001b[0m, in \u001b[0;36mDot.write\u001b[0;34m(self, path, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1660\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(s)\n\u001b[1;32m   1661\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1662\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1663\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m io\u001b[38;5;241m.\u001b[39mopen(path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m   1664\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(s)\n",
      "File \u001b[0;32m~/mbs-structural-equation-modeling/.venv/lib/python3.11/site-packages/pydot/core.py:1753\u001b[0m, in \u001b[0;36mDot.create\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1750\u001b[0m arguments \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-T\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mformat\u001b[39m)] \u001b[38;5;241m+\u001b[39m args \u001b[38;5;241m+\u001b[39m [tmp_name]\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1753\u001b[0m     stdout_data, stderr_data, process \u001b[38;5;241m=\u001b[39m \u001b[43mcall_graphviz\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m        \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworking_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmp_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1757\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1759\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n",
      "File \u001b[0;32m~/mbs-structural-equation-modeling/.venv/lib/python3.11/site-packages/pydot/core.py:142\u001b[0m, in \u001b[0;36mcall_graphviz\u001b[0;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m program_with_args \u001b[38;5;241m=\u001b[39m [program] \u001b[38;5;241m+\u001b[39m arguments\n\u001b[1;32m    133\u001b[0m process \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(\n\u001b[1;32m    134\u001b[0m     program_with_args,\n\u001b[1;32m    135\u001b[0m     env\u001b[38;5;241m=\u001b[39menv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    141\u001b[0m )\n\u001b[0;32m--> 142\u001b[0m stdout_data, stderr_data \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stdout_data, stderr_data, process\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:1207\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1207\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1209\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:2059\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2052\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   2053\u001b[0m                         stdout, stderr,\n\u001b[1;32m   2054\u001b[0m                         skip_check_and_raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2055\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[1;32m   2056\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2057\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to raise TimeoutExpired.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2059\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2060\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   2062\u001b[0m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   2063\u001b[0m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from semopy import Model\n",
    "import pydot\n",
    "import os\n",
    "\n",
    "# Load the original data\n",
    "current_directory = os.getcwd()\n",
    "survey = os.path.join(current_directory, '03-output', 'dfyale.xlsx')\n",
    "sheet_name = 'Sheet1'\n",
    "df = pd.read_excel(survey, sheet_name=sheet_name)\n",
    "\n",
    "# Identify independent columns (features) for PCA\n",
    "feature_columns = [col for col in df.columns if col.startswith('Xvar')]\n",
    "\n",
    "# Apply PCA to reduce features\n",
    "num_components = 3  # Adjust based on how much variance you want to capture\n",
    "pca = PCA(n_components=num_components)\n",
    "pca_result = pca.fit_transform(df[feature_columns])\n",
    "\n",
    "# Create a DataFrame for the PCA-transformed features\n",
    "pca_columns = [f'PC{i+1}' for i in range(num_components)]\n",
    "pca_df = pd.DataFrame(pca_result, columns=pca_columns)\n",
    "\n",
    "# Combine with dependent variables\n",
    "dependent_columns = ['Y_Q05_SupportAI']\n",
    "final_df = pd.concat([pca_df, df[dependent_columns]], axis=1)\n",
    "\n",
    "# Example SEM model with reduced PCA features\n",
    "model_desc = f\"\"\"\n",
    "# Structural Model\n",
    "Y_Q05_SupportAI ~ {' + '.join(pca_columns)}\n",
    "\"\"\"\n",
    "\n",
    "# Create the SEM model and load the dataset\n",
    "model = Model(model_desc)\n",
    "model.load_dataset(final_df)\n",
    "\n",
    "# Optimize the model\n",
    "model.fit()\n",
    "\n",
    "# Create a graph using pydot\n",
    "graph = pydot.Dot(graph_type='digraph', ratio=\"0.7\", dpi=200)\n",
    "\n",
    "# Add nodes (features) and edges (relationships) manually\n",
    "nodes = pca_columns + ['Y_Q05_SupportAI']\n",
    "for node in nodes:\n",
    "    graph.add_node(pydot.Node(node))\n",
    "\n",
    "# Add relationships (edges) between PCA components and dependent variables\n",
    "dependent_edges = [\n",
    "    ('Y_Q05_SupportAI', pca_columns)\n",
    "\n",
    "]\n",
    "\n",
    "# Add edges to the graph\n",
    "for target, sources in dependent_edges:\n",
    "    for source in sources:\n",
    "        graph.add_edge(pydot.Edge(source, target))\n",
    "\n",
    "# Extract PCA loadings for each principal component\n",
    "loadings = pd.DataFrame(pca.components_, columns=feature_columns, index=pca_columns)\n",
    "\n",
    "# Add edges representing the loadings of the original features to each principal component\n",
    "for pc, features in loadings.iterrows():\n",
    "    for feature, score in features.items():\n",
    "        graph.add_edge(pydot.Edge(feature, pc, label=f\"{score:.2f}\"))\n",
    "\n",
    "# Save the graph as a PNG image\n",
    "output_directory = os.path.join(current_directory, '04-summary')\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "graph_output_path = os.path.join(output_directory, 'sem_model_graph_unfiltered.png')\n",
    "graph.write_png(graph_output_path)\n",
    "\n",
    "# Export PCA scores and loadings to Excel for detailed analysis\n",
    "with pd.ExcelWriter(os.path.join(output_directory, 'pca_scores_and_loadings.xlsx')) as writer:\n",
    "    pca_df.to_excel(writer, sheet_name='PCA Scores', index=False)\n",
    "    loadings.to_excel(writer, sheet_name='PCA Loadings')\n",
    "\n",
    "# Print the PCA explained variance ratio\n",
    "explained_variance = pd.DataFrame({\n",
    "    \"Principal Component\": pca_columns,\n",
    "    \"Explained Variance (%)\": pca.explained_variance_ratio_ * 100\n",
    "})\n",
    "print(\"\\nPCA Explained Variance:\")\n",
    "print(explained_variance)\n",
    "\n",
    "# Save explained variance to the Excel file\n",
    "explained_variance.to_excel(os.path.join(output_directory, 'pca_explained_variance.xlsx'), index=False)\n",
    "\n",
    "print(f\"Model graph saved to: {graph_output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
