{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyreadstat\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Paths to input files and output directories\n",
    "current_directory = os.getcwd()\n",
    "sav_file_path = os.path.join(current_directory, '01-data', 'yaleoutput.sav')\n",
    "rename_excel_path = os.path.join(current_directory, '01-data', 'column_rename_mapping.xlsx')\n",
    "output_excel_path = os.path.join(current_directory, '03-output', 'dfyale.xlsx')\n",
    "\n",
    "# Read the .sav file\n",
    "df, meta = pyreadstat.read_sav(sav_file_path)\n",
    "\n",
    "# Drop the specified columns\n",
    "columns_to_drop = ['starttime', 'endtime']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Load the rename mapping from the Excel file\n",
    "rename_df = pd.read_excel(rename_excel_path, sheet_name=\"Mapping\")\n",
    "column_rename_mapping = dict(zip(rename_df['OldName'], rename_df['NewName']))\n",
    "\n",
    "# Rename the columns\n",
    "df.rename(columns=column_rename_mapping, inplace=True)\n",
    "\n",
    "# Drop columns ending in '_select'\n",
    "select_columns = [col for col in df.columns if col.endswith('_select')]\n",
    "df.drop(columns=select_columns, inplace=True)\n",
    "\n",
    "genderVar = df.filter(regex='^Xvar_gender')\n",
    "print(genderVar.info)\n",
    "\n",
    "# Get the current year\n",
    "current_year = datetime.now().year\n",
    "\n",
    "# Compute ages based on the current year\n",
    "df['age'] = current_year - df['birthyr']\n",
    "\n",
    "# Define age group bins with \"65+\" as the last group\n",
    "bins = [0, 17, 24, 34, 44, 54, 64, 100]\n",
    "labels = ['0-17', '18-24', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "\n",
    "# Categorize ages into the specified groups\n",
    "df['Xvar_age_group'] = pd.cut(df['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Convert all numerical columns to floats and round to one decimal place\n",
    "for col in df.select_dtypes(include=['number']).columns:\n",
    "    df[col] = df[col].astype(float).round(1)\n",
    "\n",
    "# Load the Grouping sheet\n",
    "grouping_df = pd.read_excel(rename_excel_path, sheet_name=\"Grouping\")\n",
    "\n",
    "# Mapping functions by suffix\n",
    "suffix_mappings = {\n",
    "    '_impact': dict(zip(grouping_df[grouping_df['Suffix'] == '_impact']['Code'], grouping_df[grouping_df['Suffix'] == '_impact']['Recode'])),\n",
    "    '_confidence': dict(zip(grouping_df[grouping_df['Suffix'] == '_confidence']['Code'], grouping_df[grouping_df['Suffix'] == '_confidence']['Recode'])),\n",
    "    '_important': dict(zip(grouping_df[grouping_df['Suffix'] == '_important']['Code'], grouping_df[grouping_df['Suffix'] == '_important']['Recode'])),\n",
    "    '_likelihood': dict(zip(grouping_df[grouping_df['Suffix'] == '_likelihood']['Code'], grouping_df[grouping_df['Suffix'] == '_likelihood']['Recode'])),\n",
    "    '_agreement': dict(zip(grouping_df[grouping_df['Suffix'] == '_agreement']['Code'], grouping_df[grouping_df['Suffix'] == '_agreement']['Recode'])),\n",
    "    'Xvar_gender': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_gender']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_gender']['Recode'])),\n",
    "    'Xvar_politics': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_politics']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_politics']['Recode'])),\n",
    "    'Xvar_Q04_01_ed_courses_CS': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_01_ed_courses_CS']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_01_ed_courses_CS']['Recode'])),\n",
    "    'Xvar_Q04_02_ed_undergrad_CS': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_02_ed_undergrad_CS']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_02_ed_undergrad_CS']['Recode'])),\n",
    "    'Xvar_Q04_03_ed_Grad_CS': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_03_ed_Grad_CS']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_03_ed_Grad_CS']['Recode'])),\n",
    "    'Xvar_Q04_04_ed_program_exp': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_04_ed_program_exp']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_04_ed_program_exp']['Recode'])),\n",
    "    'Xvar_Q04_05_ed_none': dict(zip(grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_05_ed_none']['Code'], grouping_df[grouping_df['Suffix'] == 'Xvar_Q04_05_ed_none']['Recode']))\n",
    "}\n",
    "\n",
    "# Function to recode columns based on suffix\n",
    "def apply_mapping(df, mapping_dict, suffix):\n",
    "    for col in df.columns:\n",
    "        if col.endswith(suffix):\n",
    "            df[col] = df[col].replace(mapping_dict)\n",
    "\n",
    "# Apply mappings for each suffix\n",
    "for suffix, mapping_dict in suffix_mappings.items():\n",
    "    apply_mapping(df, mapping_dict, suffix)\n",
    "\n",
    "# List of columns to be one-hot encoded\n",
    "columns_to_encode = ['Xvar_gender','Xvar_age_group','Xvar_politics', 'Xvar_Q04_01_ed_courses_CS', 'Xvar_Q04_02_ed_undergrad_CS', 'Xvar_Q04_03_ed_Grad_CS', 'Xvar_Q04_04_ed_program_exp', 'Xvar_Q04_05_ed_none']\n",
    "\n",
    "# Apply one-hot encoding (dummy variables) without converting to integers\n",
    "df_dummies = pd.get_dummies(df, columns=columns_to_encode, drop_first=False).astype(float)\n",
    "# Select specific numerical columns to round\n",
    "df_dummies[col] = df_dummies[col].astype(float).round(1)\n",
    "\n",
    "columns_to_drop = ['birthyr', 'age','race','educ','marstat','employ','faminc_new','pid7','inputstate','votereg','ideo5','newsint','religpew','pew_churatd','pew_bornagain','pew_religimp','pew_prayer','Q03new_treat','q05b_treat','q12a_treat','q12_treat','q15_treat']\n",
    "\n",
    "df_dummies = df_dummies.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "genderVar = df_dummies.filter(regex='^Xvar_gender')\n",
    "print(genderVar.info)\n",
    "\n",
    "# Save the modified DataFrame to an Excel file\n",
    "df_dummies.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(f\"DataFrame with renamed columns is saved to {output_excel_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model graph saved to: /Users/danramirez/mbs-structural-equation-modeling/04-summary/sem_model_graph.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from semopy import Model\n",
    "import pydot\n",
    "import os\n",
    "\n",
    "# Load the original data\n",
    "current_directory = os.getcwd()\n",
    "survey = os.path.join(current_directory, '03-output', 'dfyale.xlsx')\n",
    "sheet_name = 'Sheet1'\n",
    "df = pd.read_excel(survey, sheet_name=sheet_name)\n",
    "\n",
    "# Identify independent columns (features) for PCA\n",
    "feature_columns = [col for col in df.columns if col.startswith('Xvar')]\n",
    "\n",
    "# Apply PCA to reduce features\n",
    "num_components = 5  # Adjust based on how much variance you want to capture\n",
    "pca = PCA(n_components=num_components)\n",
    "pca_result = pca.fit_transform(df[feature_columns])\n",
    "\n",
    "# Create a DataFrame for the PCA-transformed features\n",
    "pca_columns = [f'PC{i+1}' for i in range(num_components)]\n",
    "pca_df = pd.DataFrame(pca_result, columns=pca_columns)\n",
    "\n",
    "# Combine with dependent variables\n",
    "dependent_columns = ['Y_Q05_SupportAI', 'Y_Q17_SupportDevHighlevelAI']\n",
    "final_df = pd.concat([pca_df, df[dependent_columns]], axis=1)\n",
    "\n",
    "# Example SEM model with reduced PCA features\n",
    "model_desc = f\"\"\"\n",
    "# Structural Model (hypothetical)\n",
    "Y_Q05_SupportAI ~ {' + '.join(pca_columns)}\n",
    "Y_Q17_SupportDevHighlevelAI ~ {' + '.join(pca_columns)}\n",
    "\"\"\"\n",
    "\n",
    "# Create the SEM model and load the dataset\n",
    "model = Model(model_desc)\n",
    "model.load_dataset(final_df)\n",
    "\n",
    "# Optimize the model\n",
    "model.fit()\n",
    "\n",
    "# Create a graph using pydot\n",
    "graph = pydot.Dot(graph_type='digraph')\n",
    "\n",
    "# Add nodes (features) and edges (relationships) manually\n",
    "nodes = pca_columns + ['Y_Q05_SupportAI', 'Y_Q17_SupportDevHighlevelAI']\n",
    "for node in nodes:\n",
    "    graph.add_node(pydot.Node(node))\n",
    "\n",
    "# Add relationships (edges) between PCA components and dependent variables\n",
    "dependent_edges = [\n",
    "    ('Y_Q05_SupportAI', pca_columns),\n",
    "    ('Y_Q17_SupportDevHighlevelAI', pca_columns)\n",
    "]\n",
    "\n",
    "# Add edges to the graph\n",
    "for target, sources in dependent_edges:\n",
    "    for source in sources:\n",
    "        graph.add_edge(pydot.Edge(source, target))\n",
    "\n",
    "# Save the graph as a PNG image\n",
    "output_directory = os.path.join(current_directory, '04-summary')\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "graph_output_path = os.path.join(output_directory, 'sem_model_graph.png')\n",
    "graph.write_png(graph_output_path)\n",
    "\n",
    "print(f\"Model graph saved to: {graph_output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
